{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvig’s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['dking', 'sport']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(\"dking sport\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>275</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>a</td>\n",
              "      <td>aaa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>a</td>\n",
              "      <td>all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>a</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192</td>\n",
              "      <td>a</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020380</th>\n",
              "      <td>24</td>\n",
              "      <td>zviad</td>\n",
              "      <td>gamsakhurdia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020381</th>\n",
              "      <td>25</td>\n",
              "      <td>zweimal</td>\n",
              "      <td>leben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020382</th>\n",
              "      <td>24</td>\n",
              "      <td>zwick</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020383</th>\n",
              "      <td>24</td>\n",
              "      <td>zydeco</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020384</th>\n",
              "      <td>72</td>\n",
              "      <td>zz</td>\n",
              "      <td>top</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1020385 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0        1             2\n",
              "0        275        a             a\n",
              "1         31        a           aaa\n",
              "2         29        a           all\n",
              "3         45        a            an\n",
              "4        192        a           and\n",
              "...      ...      ...           ...\n",
              "1020380   24    zviad  gamsakhurdia\n",
              "1020381   25  zweimal         leben\n",
              "1020382   24    zwick           and\n",
              "1020383   24   zydeco         music\n",
              "1020384   72       zz           top\n",
              "\n",
              "[1020385 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the bigrams dataset\n",
        "file = 'bigrams.txt'\n",
        "ngrams = pd.read_csv(file, sep='\\t', header=None, index_col=None, encoding='latin')\n",
        "ngrams[1] = ngrams[1].astype(str)\n",
        "ngrams[2] = ngrams[2].astype(str)\n",
        "ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "68784"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Build a vocabulary\n",
        "vocab = Counter()\n",
        "for i, row in ngrams.iterrows():\n",
        "    for word in row[1:]:\n",
        "        vocab[word] += row[0]\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base of Norvig's solution\n",
        "\n",
        "def candidates(word: str, early_known: bool = True) -> set[str]:\n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    c = known([word])\n",
        "    if not c or not early_known:\n",
        "        c |= known(edits1(word))\n",
        "    return (c or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words: list[str]): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in vocab) # Take our `vocab`\n",
        "\n",
        "def edits1(word: str) -> set[str]:\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word: str) -> set[str]: \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ding', 'doing', 'duking', 'dying', 'eking', 'king'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "candidates('dking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def editsk(word, k):\n",
        "    e = edits1(word)\n",
        "    prev = e\n",
        "    for i in range(1,k):\n",
        "        temp = set(e2 for e1 in prev for e2 in edits1(e1))\n",
        "        e.update(temp)\n",
        "        prev = temp\n",
        "    e.discard(word)\n",
        "    return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ding', 'doing', 'duking', 'dying', 'eking', 'king'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "known(editsk('dking', 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ngram_weight(ngram: list[str]) -> float:\n",
        "    \"Prior number of times of the ngram occuring.\"\n",
        "    # Assuming ngrams are sorted, apply binary search\n",
        "    lo = 0\n",
        "    hi = len(ngrams)\n",
        "    while hi > lo:\n",
        "        i = (lo + hi) // 2\n",
        "        row = ngrams.iloc[i]\n",
        "        cmp = 0\n",
        "        for j in range(len(ngram)):\n",
        "            if row[j + 1] < ngram[j]:\n",
        "                cmp = -1\n",
        "                break\n",
        "            if row[j + 1] > ngram[j]:\n",
        "                cmp = 1\n",
        "                break\n",
        "        if cmp == 0:\n",
        "            return row[0]\n",
        "        if cmp == -1:\n",
        "            lo = i + 1\n",
        "        else:\n",
        "            hi = i\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngram_weight([\"dying\", \"patient\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correct_spelling(context: list[str], incorrect: int) -> list[tuple[int, str]]:\n",
        "    \"Returns correction suggestions (with attached weights) for the word in the context.\"\n",
        "    suggestions = list(candidates(context[incorrect]))\n",
        "    if len(suggestions) < 1:\n",
        "        # No suggestions found\n",
        "        return []\n",
        "\n",
        "    # Consider corrections with their priors\n",
        "    options = []\n",
        "    max_weight = 0\n",
        "    new_context = context.copy()\n",
        "    for correction in suggestions:\n",
        "        new_context[incorrect] = correction\n",
        "        weight = ngram_weight(new_context)\n",
        "        max_weight = max(max_weight, weight)\n",
        "        options.append((weight, correction))\n",
        "\n",
        "    if max_weight == 0:\n",
        "        # No bigrams match\n",
        "        if context[incorrect] in vocab:\n",
        "            # The word is known, consider it not a mistake\n",
        "            options = [(vocab[context[incorrect]], context[incorrect])]\n",
        "        else:\n",
        "            # Select by word prior\n",
        "            for i in range(len(options)):\n",
        "                options[i] = (vocab[options[i][1]], options[i][1])\n",
        "\n",
        "    options.sort(reverse=True, key=lambda x: x[0])\n",
        "    return options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(32, 'dying'),\n",
              " (0, 'eking'),\n",
              " (0, 'duking'),\n",
              " (0, 'ding'),\n",
              " (0, 'king'),\n",
              " (0, 'doing')]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_spelling([\"dking\", \"patient\"], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(225735, 'doing'),\n",
              " (43773, 'king'),\n",
              " (19302, 'dying'),\n",
              " (180, 'ding'),\n",
              " (80, 'eking'),\n",
              " (63, 'duking')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_spelling([\"dking\", \"sports\"], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def autocorrect(sentence: str) -> str:\n",
        "    \"Attempts to autocorrect every word in the sentence\"\n",
        "    # Tokenize\n",
        "    tokenized = word_tokenize(sentence)\n",
        "    if len(tokenized) < 2:\n",
        "        # TODO\n",
        "        return sentence\n",
        "\n",
        "    # Look for unknown words - likely mistakes\n",
        "    corrected = tokenized.copy()\n",
        "    for i in range(len(tokenized)):\n",
        "        # if tokenized[i] not in vocab or (i + 1 < len(tokenized) and ngram_weight([tokenized[i], tokenized[i + 1]]) < 50):\n",
        "            # Try to correct the word by looking at both bigrams\n",
        "            correction = tokenized[i]\n",
        "            correction_weight = 0\n",
        "            if i > 0:\n",
        "                weight, word = correct_spelling([tokenized[i - 1], tokenized[i]], 1)[0]\n",
        "                if weight > correction_weight:\n",
        "                    correction_weight = weight\n",
        "                    correction = word\n",
        "            if i + 1 < len(tokenized):\n",
        "                weight, word = correct_spelling([tokenized[i], tokenized[i + 1]], 0)[0]\n",
        "                if weight > correction_weight:\n",
        "                    correction_weight = weight\n",
        "                    correction = word\n",
        "            corrected[i] = correction\n",
        "    return ' '.join(corrected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i like spots'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autocorrect(\"i liike spots\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'doing math and solving problems'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autocorrect(\"doing mth and solving problms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "*Your text here...*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>confused and frustrated, connie decides to lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>later, a woman’s scream is heard in the distance.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>christian is then paralyzed by an elder.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the temple is set on fire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>outside, the cult wails with him.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4313</th>\n",
              "      <td>confidencial also responded negatively, callin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4314</th>\n",
              "      <td>and le parisien gave the film their highest fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4315</th>\n",
              "      <td>the museum collection includes 37,000 film tit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4316</th>\n",
              "      <td>its predecessor was the dutch historical film ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4317</th>\n",
              "      <td>, 1920'sfilmstar greta garbo by alexander binder,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4318 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence\n",
              "0     confused and frustrated, connie decides to lea...\n",
              "1     later, a woman’s scream is heard in the distance.\n",
              "2              christian is then paralyzed by an elder.\n",
              "3                            the temple is set on fire.\n",
              "4                     outside, the cult wails with him.\n",
              "...                                                 ...\n",
              "4313  confidencial also responded negatively, callin...\n",
              "4314  and le parisien gave the film their highest fi...\n",
              "4315  the museum collection includes 37,000 film tit...\n",
              "4316  its predecessor was the dutch historical film ...\n",
              "4317  , 1920'sfilmstar greta garbo by alexander binder,\n",
              "\n",
              "[4318 rows x 1 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The test dataset link: https://www.kaggle.com/datasets/ved1104/wiki-sentences?resource=download\n",
        "test_df = pd.read_csv('wiki_sentences_v2.csv')\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def preprocess(s: str) -> str:\n",
        "    # Remove punctuation and make lowercase\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return s.translate(translator).lower().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_36483/3116923023.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  test_df = test_df.apply(lambda row: preprocess(row[0]), axis=1).dropna()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0       confused and frustrated connie decides to leav...\n",
              "1         later a woman’s scream is heard in the distance\n",
              "2                 christian is then paralyzed by an elder\n",
              "3                               the temple is set on fire\n",
              "4                         outside the cult wails with him\n",
              "                              ...                        \n",
              "4313    confidencial also responded negatively calling...\n",
              "4314    and le parisien gave the film their highest fi...\n",
              "4315    the museum collection includes 37000 film titl...\n",
              "4316    its predecessor was the dutch historical film ...\n",
              "4317        1920sfilmstar greta garbo by alexander binder\n",
              "Length: 4318, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preprocess the test dataset\n",
        "test_df = test_df.apply(lambda row: preprocess(row[0]), axis=1).dropna()\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_word_error(word: str, edit_distance: int = 1) -> str:\n",
        "    \"Replaces the word with a random one that is `edit_distance` away\"\n",
        "    options = list(editsk(word, edit_distance))\n",
        "    return options[random.randint(0, len(options) - 1)]\n",
        "\n",
        "def generate_errors(error_rate: float, edit_distance: int = 1):\n",
        "    \"Replaces the fixed ratio of the words with random errors `edit_distance` away\"\n",
        "    for sent in test_df:\n",
        "        words = sent.split()\n",
        "        errors = int(error_rate * len(words))\n",
        "        error_indices = random.sample(range(len(words)), min(errors, len(words)))\n",
        "        for i in error_indices:\n",
        "            words[i] = generate_word_error(words[i], edit_distance)\n",
        "        yield (sent, ' '.join(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConfusionMatrix:\n",
        "    def __init__(self):\n",
        "        self.true_pos = 0\n",
        "        self.true_neg = 0\n",
        "        self.false_pos = 0\n",
        "        self.false_neg = 0\n",
        "\n",
        "    def add(self, true: bool, positive: bool):\n",
        "        if true:\n",
        "            if positive:\n",
        "                self.true_pos += 1\n",
        "            else:\n",
        "                self.true_neg += 1\n",
        "        else:\n",
        "            if positive:\n",
        "                self.false_pos += 1\n",
        "            else:\n",
        "                self.false_neg += 1\n",
        "\n",
        "    def true(self) -> int:\n",
        "        return self.true_pos + self.true_neg\n",
        "\n",
        "    def false(self) -> int:\n",
        "        return self.false_pos + self.false_neg\n",
        "\n",
        "    def total(self) -> int:\n",
        "        return self.true() + self.false()\n",
        "            \n",
        "    def accuracy(self) -> float:\n",
        "        return self.true() / self.total()\n",
        "\n",
        "    def precision(self) -> float:\n",
        "        return self.true_pos / (self.true_pos + self.false_pos)\n",
        "\n",
        "    def recall(self) -> float:\n",
        "        return self.true_pos / (self.true_pos + self.false_neg)\n",
        "\n",
        "    def f1_score(self) -> float:\n",
        "        prec = self.precision()\n",
        "        recall = self.recall()        \n",
        "        return 2 * (prec * recall) / (prec + recall)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"\"\"\n",
        "         |  True  |  False  |\n",
        "---------+--------+---------+\n",
        "Positive |{self.true_pos:^8}|{self.false_pos:^9}|\n",
        "Negative |{self.true_neg:^8}|{self.false_neg:^9}|\n",
        "---------+--------+---------+\n",
        "\n",
        "Accuracy : {self.accuracy():.2}\n",
        "Precision: {self.precision():.2}\n",
        "Recall   : {self.recall():.2}\n",
        "F1 Score : {self.f1_score():.2}\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:55<00:00,  8.64it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "         |  True  |  False  |\n",
              "---------+--------+---------+\n",
              "Positive |  1193  |   711   |\n",
              "Negative |  8113  |   280   |\n",
              "---------+--------+---------+\n",
              "\n",
              "Accuracy : 0.9\n",
              "Precision: 0.63\n",
              "Recall   : 0.81\n",
              "F1 Score : 0.71\n",
              "        "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Test my implementation\n",
        "\n",
        "confusion = ConfusionMatrix()\n",
        "\n",
        "random.seed(69)\n",
        "for true, error in tqdm(list(generate_errors(0.2))[:1000]): #tqdm(generate_errors(2), total=len(test_df)):\n",
        "    expected = true.split()\n",
        "    errored = error.split()\n",
        "    corrected = autocorrect(error).split()\n",
        "    for i in range(len(expected)):\n",
        "        confusion.add(expected[i] == corrected[i], errored[i] != corrected[i])\n",
        "confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Norvig's solution\n",
        "\n",
        "def P(word, N=sum(vocab.values())):\n",
        "    \"Probability of `word`.\"\n",
        "    return vocab[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'spelling'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correction('speling')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'corrected'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correction('korrectud')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def norvig_correct(sentence: str) -> str:\n",
        "    corrected = [correction(word) for word in sentence.split()]\n",
        "    return ' '.join(corrected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'doing math and solving problems'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norvig_correct(\"doing mth and solving problms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:49<00:00, 20.38it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\n",
              "         |  True  |  False  |\n",
              "---------+--------+---------+\n",
              "Positive |  1181  |   689   |\n",
              "Negative |  8146  |   281   |\n",
              "---------+--------+---------+\n",
              "\n",
              "Accuracy : 0.91\n",
              "Precision: 0.63\n",
              "Recall   : 0.81\n",
              "F1 Score : 0.71\n",
              "        "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test Norvig's implementation\n",
        "\n",
        "confusion = ConfusionMatrix()\n",
        "\n",
        "random.seed(69)\n",
        "for true, error in tqdm(list(generate_errors(0.2))[:1000]): #tqdm(generate_errors(2), total=len(test_df)):\n",
        "    expected = true.split()\n",
        "    errored = error.split()\n",
        "    corrected = norvig_correct(error).split()\n",
        "    for i in range(len(expected)):\n",
        "        confusion.add(expected[i] == corrected[i], errored[i] != corrected[i])\n",
        "confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def showcase(sent: str):\n",
        "    print(f\"Original   : {sent}\")\n",
        "    print(f\"My solution: {autocorrect(sent)}\")\n",
        "    print(f\"Norvig's   : {norvig_correct(sent)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementation\n",
        "\n",
        "My solution is based on the Norvig's solution and has a few changes to incorporate context. Each word is given in the context of both bigrams (to the left and to the right). In each bigram, Norvig's solution is applied with a small difference:\n",
        "- Instead of the probability of the word occuring in the dataset, the probability of the bigram is used\n",
        "- If none of the correction suggestions give bigrams with above 0 probability, unigram probability is used (i.e. Norvig's solution)\n",
        "\n",
        "# Testing\n",
        "\n",
        "For testing, I used the [Wiki Sentences](https://www.kaggle.com/datasets/ved1104/wiki-sentences?resource=download) dataset. It is preprocessed to get rid of punctuation and upper-case. Then, in each sample 20% of the words get randomly replaced by typos that are 1 edit distance away. The model is said to produce a true positive result if it correctly identifies and changes a typo to the original word.\n",
        "\n",
        "# Results\n",
        "\n",
        "| **My solution:** |  True  |  False  | **Norvig's solution** |  True  |  False  |\n",
        "|---------|--------|---------|       ---------|--------|---------|\n",
        "|Positive |  1193  |   711   |       Positive |  1181  |   689   |\n",
        "|Negative |  8113  |   280   |       Negative |  8146  |   281   |\n",
        "|Accuracy |  0.9   |         |       Accuracy |  0.91\n",
        "|Precision|  0.63  |         |       Precision|  0.63\n",
        "|Recall   |  0.81  |         |       Recall   |  0.81\n",
        "|F1 Score |  0.71  |         |       F1 Score |  0.71\n",
        "\n",
        "The results are very similar for both solution. The likely reason for that is that most errors in the generated test dataset are do not require context to correct. If we cherry-pick sample that do require context, however, we can see that Norvig's solution fails to correct mistakes properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original   : dking patient\n",
            "My solution: dying patient\n",
            "Norvig's   : doing patient\n"
          ]
        }
      ],
      "source": [
        "showcase(\"dking patient\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original   : dking sports\n",
            "My solution: doing sports\n",
            "Norvig's   : doing sports\n"
          ]
        }
      ],
      "source": [
        "showcase(\"dking sports\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
